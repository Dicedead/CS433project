{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f9b4c3cd9d0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim, autograd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.set_num_threads(10)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Version: 3.10.7\n",
      "torch Version: 1.13.0+cu117\n",
      "torchvision Version: 0.14.0+cu117\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(f\"python Version: {sys.version.split(' ')[0]}\")\n",
    "print(f\"torch Version: {torch.__version__}\")\n",
    "print(f\"torchvision Version: {torchvision.__version__}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparameter:\n",
    "    batchsize: int          = 128\n",
    "    num_epochs: int         = 20\n",
    "    noise_size: int         = 2\n",
    "    n_critic: int           = 5\n",
    "    gp_lambda: float        = 10.\n",
    "        \n",
    "hp = Hyperparameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(hp.noise_size + 1, 256), # input: (noise , en_p)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1), # output: (dist_p)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        out = self.model(torch.cat([noise, labels], dim=1))\n",
    "        return out.squeeze()\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 512), # input: (dist_p, en_p)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, event, labels):\n",
    "        out = self.model(torch.cat([event, labels], dim=1))\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticlesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path=\"../pickled_data/water_dataset.pkl\", test_size=0.3):\n",
    "        dataset = pd.read_pickle(path)\n",
    "        dataset = dataset[dataset[\"emission\"] == 1]\n",
    "\n",
    "        x = dataset[[\"dist_p\"]]\n",
    "        y = dataset[[\"en_p\"]]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
    "\n",
    "        self.x_train=torch.from_numpy(x_train.values).float()\n",
    "        self.y_train=torch.from_numpy(y_train.values).float()\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_train[idx], self.y_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ParticlesDataset()\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=hp.batchsize, num_workers=1, shuffle=True, drop_last=True, pin_memory=True)\n",
    "critic, generator = Critic().to(\"cuda\"), Generator().to(\"cuda\")\n",
    "\n",
    "critic_optimizer = optim.AdamW(critic.parameters(), lr=1e-4, betas=(0., 0.9))\n",
    "generator_optimizer = optim.AdamW(generator.parameters(), lr=1e-4, betas=(0., 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m noise \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn((hp\u001B[38;5;241m.\u001B[39mbatchsize, hp\u001B[38;5;241m.\u001B[39mnoise_size), device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(): fake_image \u001B[38;5;241m=\u001B[39m generator(noise, real_class_labels)\n\u001B[0;32m---> 18\u001B[0m critic_output_fake \u001B[38;5;241m=\u001B[39m \u001B[43mcritic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfake_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal_class_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m critic_loss_fake \u001B[38;5;241m=\u001B[39m critic_output_fake\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m     21\u001B[0m alpha \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m1\u001B[39m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[4], line 34\u001B[0m, in \u001B[0;36mCritic.forward\u001B[0;34m(self, event, labels)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, event, labels):\n\u001B[0;32m---> 34\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\u001B[38;5;241m.\u001B[39msqueeze()\n",
      "\u001B[0;31mIndexError\u001B[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "img_list, generator_losses, critic_losses = [], [], []\n",
    "iters = 0\n",
    "grad_tensor = torch.ones((hp.batchsize, 1), device=\"cuda\")\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(hp.num_epochs):\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        real_images, real_class_labels = data[0].to(\"cuda\"), data[1].to(\"cuda\")\n",
    "        \n",
    "        # Update critic\n",
    "        critic_optimizer.zero_grad()\n",
    "        \n",
    "        critic_output_real = critic(real_images, real_class_labels)\n",
    "        critic_loss_real = critic_output_real.mean()\n",
    "\n",
    "        noise = torch.randn((hp.batchsize, hp.noise_size), device=\"cuda\")\n",
    "        with torch.no_grad(): fake_image = generator(noise, real_class_labels)\n",
    "        critic_output_fake = critic(fake_image, real_class_labels)\n",
    "        critic_loss_fake = critic_output_fake.mean()\n",
    "\n",
    "        alpha = torch.rand(1, device=\"cuda\")\n",
    "        interpolates = (alpha * real_images + (1. - alpha) * fake_image).requires_grad_(True)\n",
    "        d_interpolates = critic(interpolates, real_class_labels).reshape(-1, 1)\n",
    "        gradients = autograd.grad(d_interpolates, interpolates, grad_tensor, create_graph=True, only_inputs=True)[0]\n",
    "        gradient_penalty = hp.gp_lambda * ((gradients.view(hp.batchsize, -1).norm(dim=1) - 1.) ** 2).mean()\n",
    "\n",
    "        critic_loss = -critic_loss_real + critic_loss_fake  + gradient_penalty\n",
    "        \n",
    "        critic_loss.backward()\n",
    "        critic_optimizer.step()\n",
    "\n",
    "        if batch_idx % hp.n_critic == 0:\n",
    "            # Update Generator\n",
    "            generator_optimizer.zero_grad()\n",
    "            \n",
    "            fake_class_labels = dataset.y_train[torch.randint(high=len(dataset), size=[hp.batchsize])].to(device=\"cuda\")\n",
    "            noise = torch.randn((hp.batchsize, hp.noise_size), device=\"cuda\")\n",
    "            fake_image = generator(noise, fake_class_labels)\n",
    "            critic_output_fake = critic(fake_image, fake_class_labels)\n",
    "            generator_loss = -critic_output_fake.mean()\n",
    "            \n",
    "            generator_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if batch_idx % 100 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"[{epoch:>2}/{hp.num_epochs}][{iters:>7}][{elapsed_time:8.2f}s]\\t\"\n",
    "                  f\"d_loss/g_loss: {critic_loss.item():4.2}/{generator_loss.item():4.2}\\t\")\n",
    "       \n",
    "        # Save Losses for plotting later\n",
    "        generator_losses.append(generator_loss.item())\n",
    "        critic_losses.append(critic_loss.item())\n",
    "            \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b929b525c3ad5b5165d0d1ea767dbde287d9c26320fa3889726f679d0a1bb497"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
